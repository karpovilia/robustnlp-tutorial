---
title: EMNLP 21 Tutorial on Robust NLP 
layout: page
permalink: /
---

## Overview


Recent advances in data-driven machine learning techniques such as deep neural networks have revolutionized natural language processing. In particular, modern natural language processing (NLP) systems have achieved outstanding performance on various tasks such as question answering, textual entailment, language generation. In many cases, they even achieve higher performance than inter-annotator agreement on benchmark datasets. It may be tempting to conclude from results on these **datasets** that current systems are as good as humans at these NLP **tasks**.


Despite the remarkable success, recent studies show that these systems often rely on spurious correlations and fail catastrophically when given inputs from different sources or inputs that have been adversarially perturbed. For example, Jie et.al. 2017 show that state-of-the-art reading comprehension systems fail to answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer. Similarly, a series of studies demonstrate that text classification models are not robust against adversarial examples that generated by synonym substitution, paraphrasing, and inserting/deleting characters in the text input. This lack of robustness exposes troubling gaps in current models' language understanding capabilities and creates problems when NLP systems are deployed to real users.


As NLP systems are increasingly integrated into people's daily lives and directly interact with end-users, it is essential to ensure their reliability. For example, systems that flag hateful social media content for review must be robust to adversaries who wish to evade detection. Defending against these threats requires building systems that are robust to whatever alterations an attacker might apply to text in order to achieve the desired classifier behavior. Besides, even if systems perform well on user queries on average,
rare but catastrophic errors can lead to serious issues. In 2017, Facebook's machine translation system mistakenly translated an Arabic Facebook post with the message "Good morning" into a Hebrew phrase that meant ``Attack them''.
As a result, the Israeli police arrested the man who made the post and detained him for several hours until the misunderstanding is resolved.
Therefore, deployed systems must avoid egregious errors like wrongly translating non-violent messages into violent ones and should be tested on "worst-case" non-violent messages.



In this tutorial, we will review the history of adversarial example generation and methods for enhancing robustness of NLP systems.
We will provide  the  audience  with  a  holistic  view  of 1) how to use adversarial examples to examinethe weakness of NLP models and facilitate de-bugging; 2) how to enhance the robustness ofexisting NLP models and defense against ad-versarial inputs; and 3) how the considerationof robustness affects the real-world NLP appli-cations used in our daily lives.

## Speakers
<div class="col-md-3">
    <div class="profile height150">
        <div><a href="http://kwchang.net"><img class="avatar-img" width=150 src="https://avatars2.githubusercontent.com/kaiweichang?v=3&s=400"></a></div>
        <div style="margin-bottom:40px"><center><b>Kai-Wei Chang</b><br> UCLA</center></div>
    </div>
</div>

<div class="col-md-3">
    <div class="profile height150">
        <div><a href="https://hhexiy.github.io/"><img class="avatar-img" width=150 src="images/he.png"> </a></div>
        <div style="margin-bottom:40px"><center><b> He He</b> <br> NYU </center></div>
    </div>
</div>
<div class="col-md-3">
    <div class="profile height150">
        <div><a href="https://robinjia.github.io/"><img class="avatar-img" width=150 src="https://avatars2.githubusercontent.com/robinjia?v=3&s=400"></a></div>
        <div style="margin-bottom:40px"><center><b>Robin Jia</b><br> USC</center></div>
    </div>
</div>

<div class="col-md-3">
    <div class="profile height150">
        <div><a href="https://sameersingh.org/"><img class="avatar-img" width=150 src="images/sameer.png"></a></div>
        <div style="margin-bottom:40px"><center><b>Sameer Singh</b><br> UC Irvine</center></div>
    </div>
</div>

## Slides
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQObhZjgRpHPVStVU2V87P-E4LgsD764B2bY4CUOhOEhORPMXQOnKpmxmtoePFvBW81NDrCn3VaOAT8/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
