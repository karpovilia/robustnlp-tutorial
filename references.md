---
layout: page
title: References 
permalink: /references
---


## References

### Writing Challenging Examples
1. **Beyond Accuracy: Behavioral Testing of NLP Models with CheckList**. *Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, Sameer Singh*. ACL 2020. [[pdf](https://aclanthology.org/2020.acl-main.442.pdf)]
1. **Evaluating Models’ Local Decision Boundaries via Contrast Sets**. *Matt Gardner, Yoav Artzi, Victoria Basmov, Jonathan Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi, Dheeru Dua, Yanai Elazar, Ananth Gottumukkala, Nitish Gupta, Hannaneh Hajishirzi, Gabriel Ilharco, Daniel Khashabi, Kevin Lin, Jiangming Liu, Nelson F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer Singh, Noah A. Smith, Sanjay Subramanian, Reut Tsarfaty, Eric Wallace, Ally Zhang, Ben Zhou*. Findings of EMNLP 2020. [[pdf](https://aclanthology.org/2020.findings-emnlp.117.pdf)]
1. **Learning the Difference that Makes a Difference with Counterfactually-Augmented Data**. *Divyansh Kaushik, Eduard Hovy, Zachary C. Lipton*. ICLR 2020. [[pdf](https://arxiv.org/pdf/1909.12434.pdf)]
1. **DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs**. *Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, Matt Gardner*. NAACL 2019. [[pdf](https://aclanthology.org/N19-1246.pdf)]
1. **Trick Me If You Can: Human-in-the-loop Generation of Adversarial Question Answering Examples**. *Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Yamada, Jordan Boyd-Graber*. TACL 2019. [[pdf](https://arxiv.org/pdf/1809.02701.pdf)]
1. **Adversarial NLI: A New Benchmark for Natural Language Understanding**. *Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, Douwe Kiela*. ACL 2020. [[pdf](https://aclanthology.org/2020.acl-main.441.pdf)]
1. **Dynabench: Rethinking Benchmarking in NLP**. *Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, Adina Williams*. NAACL 2021. [[pdf](https://aclanthology.org/2021.naacl-main.324.pdf)]
1. **SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference**. *Rowan Zellers, Yonatan Bisk, Roy Schwartz, Yejin Choi*. EMNLP 2018. [[pdf](https://aclanthology.org/D18-1009.pdf)]
1. **Adversarial Filters of Dataset Biases**. *Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers, Matthew E. Peters, Ashish Sabharwal, Yejin Choi*. ICML 2020. [[pdf](https://arxiv.org/pdf/2002.04108.pdf)]


### Finding Lack of Robustness (Attacks)
1. **Generating Natural Adversarial Examples**. *Zhengli Zhao, Dheeru Dua, Sameer Singh*. ICLR 2018. [[pdf](https://arxiv.org/abs/1710.11342)]
1. **Semantically Equivalent Adversarial Rules for Debugging NLP models**. *Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin*. ACL 2018.
1. **Generating Natural Language Adversarial Examples**. *Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, Kai-Wei Chang*. EMNLP 2018. [[pdf](https://www.aclweb.org/anthology/D18-1316)]
1. **Universal Adversarial Triggers for Attacking and Analyzing NLP**. *Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh*. EMNLP-IJCNLP 2019. [[pdf](https://aclanthology.org/D19-1221.pdf)]
1. **Adversarial Semantic Collisions**. *Congzheng Song, Alexander M. Rush, Vitaly Shmatikov*. EMNLP 2020.
1. **Universal Adversarial Attacks with Natural Triggers for Text Classification**. *Liwei Song, Xinwei Yu, Hsuan-Tung Peng, Karthik Narasimhan*. NAACL 2021.
1. Surveys:
    1. **Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey**. *Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, Chenliang Li*. [[link](https://arxiv.org/abs/1901.06796)]
    1. **Towards a Robust Deep Neural Network in Texts: A Survey**. *Wenqi Wang, Run Wang, Lina Wang, Zhibo Wang, Aoshuang Ye*. [[link](https://arxiv.org/abs/1902.07285)]
    1. **Analysis Methods in Neural Language Processing: A Survey**. *Yonatan Belinkov, James Glass*. TACL 2019. [[link](https://aclanthology.org/Q19-1004/)]
    1. **Adversarial Attacks and Defenses in Images, Graphs and Text: A Review**. *Han Xu, Yao Ma, Haochen Liu, Debayan Deb, Hui Liu, Jiliang Tang, Anil K. Jain*. [[link](https://arxiv.org/abs/1909.08072)]
    1. **Adversarial Attacks and Defense on Texts: A Survey**. *Aminul Huq, Mst. Tasnim Pervin*. [[link](https://arxiv.org/abs/2005.14108)]
    1. thuNLP list of **Must-read Papers on Textual Adversarial Attack and Defense (TAAD)** [[link](https://github.com/thunlp/TAADpapers)]


### Making Models Robust (Defenses)
1. **Defense against Synonym Substitution-based Adversarial Attacks via Dirichlet Neighborhood Ensemble**. *Yi Zhou, Xiaoqing Zheng, Cho-Jui Hsieh, Kai-Wei Chang, Xuanjing Huang*. ACL-IJCNLP 2021. [[pdf](https://aclanthology.org/2021.acl-long.426.pdf)]
1. **Adversarial Training with Fast Gradient Projection Method against Synonym Substitution based Text Attacks**. *Xiaosen Wang, Yichen Yang, Yihe Deng, Kun He*. AAAI 2021. [[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/17648/17455)] 
1. **FreeLB: Enhanced Adversarial Training for Language Understanding**. *Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, Jingjing Liu*. CoRR 2019. [[pdf](https://arxiv.org/pdf/1909.11764.pdf)]
1. **Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification**. *Yichao Zhou, Jyun-Yu Jiang, Kai-Wei Chang, Wei Wang*. EMNLP-IJCNLP 2019. [[pdf](https://www.aclweb.org/anthology/D19-1496.pdf)]

### Certified Robustness
1. **Certified Robustness to Adversarial Word Substitutions**. *Robin Jia, Aditi Raghunathan, Kerem Göksel, Percy Liang*. EMNLP 2019. [[pdf](https://aclanthology.org/D19-1423.pdf)]
1. **Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation**. *Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani Yogatama, Sven Gowal, Krishnamurthy Dvijotham, Pushmeet Kohli*. EMNLP 2019. [[pdf](https://aclanthology.org/D19-1419.pdf)]
1. **Robustness Verification for Transformers**. *Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh*. ICLR 2020. [[pdf](https://arxiv.org/pdf/2002.06622.pdf)]
1. **Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond**. *Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya Kailkhura, Xue Lin, Cho-Jui Hsieh*. NeurIPS 2020. [[pdf](https://arxiv.org/pdf/2002.12920.pdf)]
1. **Robust Encodings: A Framework for Combating Adversarial Typos**. *Erik Jones, Robin Jia, Aditi Raghunathan, Percy Liang*. ACL 2020. [[pdf](https://aclanthology.org/2020.acl-main.245.pdf)]
1. **Certified Adversarial Robustness via Randomized Smoothing**. *Jeremy M Cohen, Elan Rosenfeld, J. Zico Kolter*. ICML 2019. [[pdf](https://arxiv.org/pdf/1902.02918.pdf)]
1. **SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions**. *Mao Ye, Chengyue Gong, Qiang Liu*. ACL 2020. [[pdf](https://aclanthology.org/2020.acl-main.317.pdf)]

More related papers can be found at [https://github.com/thunlp/TAADpaper](https://github.com/thunlp/TAADpaper).
